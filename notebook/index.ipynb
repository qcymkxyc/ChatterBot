{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# 模型保存路径\n",
    "model_path = \"../model/\"\n",
    "# 数据路径\n",
    "data_path = \"../data/corpus/ass.out\"\n",
    "seq2seq_model_name = \"seq2seq.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tf.enable_eager_execution must be called at program startup.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-306abcf18686>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimp\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreload\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq2seq_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36menable_eager_execution\u001b[1;34m(config, device_policy, execution_mode)\u001b[0m\n\u001b[0;32m   5421\u001b[0m         \u001b[0mdevice_policy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice_policy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5422\u001b[0m         \u001b[0mexecution_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5423\u001b[1;33m         server_def=None)\n\u001b[0m\u001b[0;32m   5424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36menable_eager_execution_internal\u001b[1;34m(config, device_policy, execution_mode, server_def)\u001b[0m\n\u001b[0;32m   5465\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgraph_mode_has_been_used\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5466\u001b[0m       raise ValueError(\n\u001b[1;32m-> 5467\u001b[1;33m           \"tf.enable_eager_execution must be called at program startup.\")\n\u001b[0m\u001b[0;32m   5468\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_execution_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEAGER_MODE\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5469\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: tf.enable_eager_execution must be called at program startup."
     ]
    }
   ],
   "source": [
    "import seq2seq_model\n",
    "from imp import reload\n",
    "reload(seq2seq_model)\n",
    "tf.contrib.eager.enable_eager_execution()\n",
    "\n",
    "x = np.random.normal(size=(100, 100, 10))\n",
    "y = np.random.normal(size=(100, 100, 10))\n",
    "z = np.random.normal(size=(100, 100, 10))\n",
    "\n",
    "input_dim = 10\n",
    "encoder_units = [10,20,30]\n",
    "decoder_units = [10,20,30]\n",
    "hidden_units = [40,40]\n",
    "batch_size = 10\n",
    "\n",
    "\n",
    "model = seq2seq_model.build_seq2seq(\n",
    "    input_dim=input_dim,\n",
    "    encoder_units=encoder_units,\n",
    "    decoder_units=decoder_units,\n",
    "    batch_size=batch_size,\n",
    "    hidden_units=hidden_units\n",
    ")\n",
    "# model.compile(optimizer=tf.train.AdamOptimizer(), loss='categorical_crossentropy')\n",
    "# model.fit([x, y], z, batch_size = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_Input (InputLayer)      (None, None, 10)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Input (InputLayer)      (10, None, 10)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_LSTM_1 (CuDNNLSTM)      [(None, None, 10), ( 880         Encoder_Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM_1 (CuDNNLSTM)      [(10, None, 10), (10 880         Decoder_Input[0][0]              \n",
      "                                                                 Encoder_LSTM_1[0][1]             \n",
      "                                                                 Encoder_LSTM_1[0][2]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_LSTM_2 (CuDNNLSTM)      [(None, None, 20), ( 2560        Encoder_LSTM_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM_2 (CuDNNLSTM)      [(10, None, 20), (10 2560        Decoder_LSTM_1[0][0]             \n",
      "                                                                 Encoder_LSTM_2[0][1]             \n",
      "                                                                 Encoder_LSTM_2[0][2]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_LSTM_3 (CuDNNLSTM)      [(None, None, 30), ( 6240        Encoder_LSTM_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM_3 (CuDNNLSTM)      [(10, None, 30), (10 6240        Decoder_LSTM_2[0][0]             \n",
      "                                                                 Encoder_LSTM_3[0][1]             \n",
      "                                                                 Encoder_LSTM_3[0][2]             \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_hidden_1 (Dense)        (10, None, 40)       1240        Decoder_LSTM_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_hidden_2 (Dense)        (10, None, 40)       1640        Decoder_hidden_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (10, None, 10)       410         Decoder_hidden_2[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 22,650\n",
      "Trainable params: 22,650\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 751ms/step - loss: 0.0152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1832b278>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(), loss='categorical_crossentropy')\n",
    "model.fit([x, y], z, batch_size = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "!head \"../data/corpus/ass.out\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":美战之星字幕组\n",
      "\n",
      "月光水晶城\n",
      "\n",
      "翻 译\n",
      "\n",
      "明月\n",
      "\n",
      "之心\n",
      "\n",
      "校 对\n",
      "\n",
      "心月\n",
      "\n",
      "晓雪\n",
      "\n",
      "时间轴制作\n",
      "\n",
      "飞天\n",
      "\n",
      "圣明\n",
      "\n",
      "特 效\n",
      "\n",
      "心月\n",
      "\n",
      "晓雪\n",
      "\n",
      "监督\n",
      "\n",
      "新月\n",
      "\n",
      "冰冰\n",
      "\n",
      "小小兔变得有精神了\n",
      "\n",
      "而我却还没能喘口气\n",
      "\n",
      "她就又跑来缠着小卫了\n",
      "\n",
      "心有不甘的我去狂吃蛋糕\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(data_path, encoding=\"utf-8\") as f:\n",
    "    for i,v in enumerate(f):\n",
    "        print(v)\n",
    "        if i == 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 1000\n",
    "t = list()\n",
    "with open(data_path, encoding=\"utf-8\") as f:\n",
    "    for i, v in enumerate(f):\n",
    "        if i == samples:\n",
    "            break\n",
    "        t.append(v)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "t1 = list()\n",
    "\n",
    "for v in t:\n",
    "    words = jieba.cut(v)\n",
    "    t1.append(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 259,  260,  261, ...,    0,    0,    0],\n",
       "       [ 113,  366,    0, ...,    0,    0,    0],\n",
       "       [ 262,  195,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  73,    6,    0, ...,    0,    0,    0],\n",
       "       [  73, 1329,    5, ...,    0,    0,    0],\n",
       "       [  11,   11,   32, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import text as T\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=None)\n",
    "tokenizer.fit_on_texts(t1)\n",
    "t2 = tokenizer.texts_to_sequences(t1)\n",
    "x = pad_sequences(t2,maxlen=100,padding=\"post\")\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1330"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "import seq2seq_model\n",
    "\n",
    "batch_size = 10\n",
    "encoder_units = [128,128,128]\n",
    "decoder_units = encoder_units\n",
    "voc_size = len(tokenizer.word_counts)\n",
    "hidden_units = [128,64]\n",
    "input_dim = voc_size\n",
    "seq_length = 100\n",
    "epoch = 10\n",
    "\n",
    "reload(seq2seq_model)\n",
    "model = seq2seq_model.build_seq2seq(\n",
    "                    batch_size=batch_size,\n",
    "                    encoder_units=encoder_units,\n",
    "                    decoder_units=decoder_units,\n",
    "                    voc_size=voc_size,\n",
    "                    input_dim=input_dim,\n",
    "                    seq_length = seq_length,\n",
    "                    hidden_units=hidden_units\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_Input (InputLayer)      (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 100, 300)     399000      Encoder_Input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Input (InputLayer)      (10, None, 1330)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_LSTM_1 (CuDNNLSTM)      [(None, 100, 128), ( 220160      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM_1 (CuDNNLSTM)      [(10, None, 128), (N 747520      Decoder_Input[0][0]              \n",
      "                                                                 Encoder_LSTM_1[0][1]             \n",
      "                                                                 Encoder_LSTM_1[0][2]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_LSTM_2 (CuDNNLSTM)      [(None, 100, 128), ( 132096      Encoder_LSTM_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM_2 (CuDNNLSTM)      [(10, None, 128), (N 132096      Decoder_LSTM_1[0][0]             \n",
      "                                                                 Encoder_LSTM_2[0][1]             \n",
      "                                                                 Encoder_LSTM_2[0][2]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_LSTM_3 (CuDNNLSTM)      [(None, 100, 128), ( 132096      Encoder_LSTM_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM_3 (CuDNNLSTM)      [(10, None, 128), (N 132096      Decoder_LSTM_2[0][0]             \n",
      "                                                                 Encoder_LSTM_3[0][1]             \n",
      "                                                                 Encoder_LSTM_3[0][2]             \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_hidden_1 (Dense)        (10, None, 128)      16512       Decoder_LSTM_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_hidden_2 (Dense)        (10, None, 64)       8256        Decoder_hidden_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (10, None, 1330)     86450       Decoder_hidden_2[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 2,006,282\n",
      "Trainable params: 2,006,282\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, label = list(),list()\n",
    "for i,seq in enumerate(x):\n",
    "    if i % 2 == 0:\n",
    "        data.append(seq)\n",
    "    else:\n",
    "        label.append(seq)\n",
    "\n",
    "data = np.asarray(data)\n",
    "label = np.asarray(label)\n",
    "\n",
    "len(data),len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "x2 = list()\n",
    "for i, v in enumerate(label):\n",
    "    x2_v = copy.copy(v)\n",
    "    x2_v = x2_v.tolist()\n",
    "    x2_v.insert(0,0)\n",
    "    x2_v = x2_v[:seq_length]\n",
    "    x2.append(x2_v)\n",
    "    \n",
    "x2 = np.asarray(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def one_hot_encode(data,voc_size):\n",
    "    \"\"\"one_hot编码数据\"\"\"\n",
    "    data_length,seq_length = data.shape\n",
    "    enc = OneHotEncoder(n_values=voc_size,sparse=False)\n",
    "    t = enc.fit_transform(data)\n",
    "    t.shape = (data_length,seq_length,voc_size)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flag = True\n",
    "if flag:\n",
    "    x2 = one_hot_encode(x2,voc_size)\n",
    "    y = one_hot_encode(label,voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 100), (500, 100, 1330), (500, 100, 1330))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = data\n",
    "x1.shape,x2.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      "450/450 [==============================] - 7s 16ms/step - loss: 2.3624 - val_loss: 0.3561\n",
      "Epoch 2/10\n",
      "450/450 [==============================] - 5s 11ms/step - loss: 0.3647 - val_loss: 0.3437\n",
      "Epoch 3/10\n",
      "450/450 [==============================] - 5s 11ms/step - loss: 0.3541 - val_loss: 0.3508\n",
      "Epoch 4/10\n",
      "450/450 [==============================] - 5s 11ms/step - loss: 0.3476 - val_loss: 0.3599\n",
      "Epoch 5/10\n",
      "450/450 [==============================] - 5s 11ms/step - loss: 0.3451 - val_loss: 0.3625\n",
      "Epoch 6/10\n",
      "450/450 [==============================] - 5s 11ms/step - loss: 0.3434 - val_loss: 0.3759\n",
      "Epoch 7/10\n",
      "450/450 [==============================] - 5s 11ms/step - loss: 0.3287 - val_loss: 0.3655\n",
      "Epoch 8/10\n",
      "450/450 [==============================] - 5s 11ms/step - loss: 0.3151 - val_loss: 0.3732\n",
      "Epoch 9/10\n",
      "450/450 [==============================] - 5s 11ms/step - loss: 0.3076 - val_loss: 0.3780\n",
      "Epoch 10/10\n",
      "450/450 [==============================] - 5s 12ms/step - loss: 0.3006 - val_loss: 0.3887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x5e6fdef0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "epoch = 10\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), loss='categorical_crossentropy')\n",
    "model.fit([x1,x2],y,batch_size=batch_size,epochs=epoch,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer Decoder_LSTM_1 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM_1_3/strided_slice_17:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM_1_3/strided_slice_18:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "WARNING:tensorflow:Layer Decoder_LSTM_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM_2_3/strided_slice_17:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM_2_3/strided_slice_18:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "WARNING:tensorflow:Layer Decoder_LSTM_3 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM_3_3/strided_slice_17:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM_3_3/strided_slice_18:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "seq2seq_model_name = \"seq2seq.h5\"\n",
    "\n",
    "model.save(os.path.join(model_path,seq2seq_model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model = keras.models.load_model(os.path.join(model_path,seq2seq_model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Encoder_Input_1:0\", shape=(?, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoder_input_layer = model.input[0]\n",
    "print(encoder_input_layer)\n",
    "\n",
    "encoder_state_list = list()\n",
    "for i in range(len(encoder_units)):\n",
    "    layer = model.get_layer(\"Encoder_LSTM_{}\".format(i + 1))\n",
    "    encoder_state_list.append((layer.output[1],layer.output[2]))\n",
    "\n",
    "# print(encoder_state_list)\n",
    "\n",
    "encoder_output_states = list()\n",
    "for v in encoder_state_list:\n",
    "    encoder_output_states += v\n",
    "encoder = keras.Model(inputs = encoder_input_layer, outputs= encoder_output_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, 100, 128), (None, 128), (None, 128)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder_Input (InputLayer)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          399000    \n",
      "_________________________________________________________________\n",
      "Encoder_LSTM_1 (CuDNNLSTM)   [(None, 100, 128), (None, 220160    \n",
      "_________________________________________________________________\n",
      "Encoder_LSTM_2 (CuDNNLSTM)   [(None, 100, 128), (None, 132096    \n",
      "_________________________________________________________________\n",
      "Encoder_LSTM_3 (CuDNNLSTM)   [(None, 100, 128), (None, 132096    \n",
      "=================================================================\n",
      "Total params: 883,352\n",
      "Trainable params: 883,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input.shape\n",
    "# decoder_input.set_shape([1,None,1330])\n",
    "\n",
    "decoder_input.set_shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder_input = model.input[1]\n",
    "\n",
    "decoder_state_input_list = []\n",
    "decoder_state_list = []\n",
    "for i,unit in enumerate(decoder_units):\n",
    "    decoder_state_input_h = keras.layers.Input(shape=(unit,),name=\"State_h_Input_{}\".format(i + 1))\n",
    "    decoder_state_input_c = keras.layers.Input(shape=(unit,),name=\"State_c_Input_{}\".format(i + 1))\n",
    "    decoder_states_input = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_state_input_list.append(decoder_states_input)\n",
    "\n",
    "last_lstm_layer = decoder_input\n",
    "for i in range(len(decoder_units)):\n",
    "    lstm_layer = model.get_layer(\"Decoder_LSTM_{}\".format(i + 1))\n",
    "    \n",
    "    decoder_output,state_h,state_c = lstm_layer(\n",
    "            inputs = last_lstm_layer,\n",
    "            initial_state=decoder_state_input_list[i]\n",
    "        )\n",
    "    decoder_state_list.append((state_h,state_c))\n",
    "    last_lstm_layer = decoder_output\n",
    "\n",
    "\n",
    "hidden1 = model.get_layer(\"Decoder_hidden_{}\".format(1))\n",
    "last_layer = last_lstm_layer\n",
    "for i in range(len(hidden_units)):\n",
    "    hidden_layer = model.get_layer(\"Decoder_hidden_{}\".format(i + 1))\n",
    "    output = hidden_layer(inputs = last_layer)\n",
    "    last_layer = output\n",
    "\n",
    "c = list()\n",
    "for a in decoder_state_input_list:\n",
    "    c += a\n",
    "decoder_state_input_list = c\n",
    "states = []\n",
    "for i in decoder_state_list:\n",
    "    states += i\n",
    "decoder_state_list = states\n",
    "decoder = keras.Model([decoder_input]+c,[output] + decoder_state_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder_Input (InputLayer)      (10, None, 1330)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "State_h_Input_1 (InputLayer)    (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "State_c_Input_1 (InputLayer)    (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM_1 (CuDNNLSTM)      [(10, None, 128), (N 747520      Decoder_Input[0][0]              \n",
      "                                                                 State_h_Input_1[0][0]            \n",
      "                                                                 State_c_Input_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "State_h_Input_2 (InputLayer)    (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "State_c_Input_2 (InputLayer)    (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM_2 (CuDNNLSTM)      [(10, None, 128), (N 132096      Decoder_LSTM_1[1][0]             \n",
      "                                                                 State_h_Input_2[0][0]            \n",
      "                                                                 State_c_Input_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "State_h_Input_3 (InputLayer)    (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "State_c_Input_3 (InputLayer)    (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM_3 (CuDNNLSTM)      [(10, None, 128), (N 132096      Decoder_LSTM_2[1][0]             \n",
      "                                                                 State_h_Input_3[0][0]            \n",
      "                                                                 State_c_Input_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_hidden_1 (Dense)        (10, None, 128)      16512       Decoder_LSTM_3[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_hidden_2 (Dense)        (10, None, 64)       8256        Decoder_hidden_1[1][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,036,480\n",
      "Trainable params: 1,036,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq = [113,260,195]\n",
    "seq = [113,260,195] + [0] * 100\n",
    "seq = seq[:100]\n",
    "\n",
    "s = [seq]\n",
    "s = np.asarray(s)\n",
    "s.shape\n",
    "p = encoder.predict(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(p[0])\n",
    "c = []\n",
    "for i in range(6):\n",
    "    q = np.zeros([1,128])\n",
    "    c.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1330)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Encoder_Input_1' with dtype float and shape [?,100]\n\t [[{{node Encoder_Input_1}} = Placeholder[dtype=DT_FLOAT, shape=[?,100], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node Decoder_LSTM_1_2/strided_slice_17/_357}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1353_Decoder_LSTM_1_2/strided_slice_17\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-ea61a82e590f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# decoder.predict(a,batch_size=1,)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1876\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1877\u001b[0m       return training_arrays.predict_loop(\n\u001b[1;32m-> 1878\u001b[1;33m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1880\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, inputs, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2986\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Encoder_Input_1' with dtype float and shape [?,100]\n\t [[{{node Encoder_Input_1}} = Placeholder[dtype=DT_FLOAT, shape=[?,100], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node Decoder_LSTM_1_2/strided_slice_17/_357}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1353_Decoder_LSTM_1_2/strided_slice_17\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "# print(p[0].shape)\n",
    "se = np.zeros((1,1,voc_size))\n",
    "se[0,0,89] = 1\n",
    "a = [se] + c \n",
    "# print(a)\n",
    "print(se.shape)\n",
    "# decoder.predict(a,batch_size=1,)\n",
    "decoder.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# keras.utils.plot_model(decoder, to_file='../images/decoder.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取回答语句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Decoder_Input_1:0' shape=(10, ?, 1330) dtype=float32>,\n",
       " <tf.Tensor 'State_h_Input_1_1:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'State_c_Input_1_1:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'State_h_Input_2_1:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'State_c_Input_2_1:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'State_h_Input_3_1:0' shape=(?, 128) dtype=float32>,\n",
       " <tf.Tensor 'State_c_Input_3_1:0' shape=(?, 128) dtype=float32>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index[\"怎么\"]\n",
    "# \" \".join(jieba.cut(\"\"))\n",
    "# t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Encoder_Input_1' with dtype float and shape [?,100]\n\t [[{{node Encoder_Input_1}} = Placeholder[dtype=DT_FLOAT, shape=[?,100], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node Decoder_LSTM_3_5/strided_slice_17/_371}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2594_Decoder_LSTM_3_5/strided_slice_17\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-fe046b5dce8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdecoder_seq\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0manswer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"怎么了\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-69-fe046b5dce8e>\u001b[0m in \u001b[0;36manswer\u001b[1;34m(input_seq, max_length)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mdecoder_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvoc_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#     print(decoder_seq.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdecoder_seq\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"怎么了\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1876\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1877\u001b[0m       return training_arrays.predict_loop(\n\u001b[1;32m-> 1878\u001b[1;33m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1880\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, inputs, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2984\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2986\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Encoder_Input_1' with dtype float and shape [?,100]\n\t [[{{node Encoder_Input_1}} = Placeholder[dtype=DT_FLOAT, shape=[?,100], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\t [[{{node Decoder_LSTM_3_5/strided_slice_17/_371}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_2594_Decoder_LSTM_3_5/strided_slice_17\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "def answer(input_seq,max_length):\n",
    "    \"\"\"回答\n",
    "    Args:\n",
    "        input_seq: str\n",
    "            问题，输入的话\n",
    "        max_length: int\n",
    "            最大回答长度\n",
    "    Return: str\n",
    "        回答的话\n",
    "    \"\"\"\n",
    "    words = list(jieba.cut(input_seq))\n",
    "    words = [tokenizer.word_index.get(word,0) for word in words]\n",
    "    words = words + [0] * seq_length\n",
    "    words = words[:seq_length]\n",
    "    q_nums = np.asarray([words])\n",
    "    \n",
    "    encoder_states = encoder.predict(q_nums)\n",
    "#     print(encoder_states[0])\n",
    "    decoder_seq = np.zeros((1,1,voc_size))\n",
    "#     print(decoder_seq.shape)\n",
    "    decoder.predict([decoder_seq] + encoder_states)\n",
    "\n",
    "answer(\"怎么了\",100)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "227px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
